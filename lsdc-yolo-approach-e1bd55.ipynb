{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":193298353,"sourceType":"kernelVersion"},{"sourceId":193335312,"sourceType":"kernelVersion"},{"sourceId":193338638,"sourceType":"kernelVersion"},{"sourceId":193417638,"sourceType":"kernelVersion"},{"sourceId":199620467,"sourceType":"kernelVersion"},{"sourceId":199888517,"sourceType":"kernelVersion"},{"sourceId":199977556,"sourceType":"kernelVersion"},{"sourceId":100132,"sourceType":"modelInstanceVersion","modelInstanceId":64905,"modelId":89293}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --no-index --find-links /kaggle/input/ultralytics ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:22:47.620926Z","iopub.execute_input":"2024-10-07T14:22:47.621527Z","iopub.status.idle":"2024-10-07T14:23:01.968246Z","shell.execute_reply.started":"2024-10-07T14:22:47.621495Z","shell.execute_reply":"2024-10-07T14:23:01.966978Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile convert_dcm.py \n\nimport os\nimport pydicom\nfrom PIL import Image\nimport numpy as np\nfrom multiprocessing import Pool, cpu_count\n\nimport sklearn.metrics\nimport torch\nimport cv2\nimport numpy as np \nimport pandas as pd \nfrom tqdm.auto import tqdm\nIMG_DIR = '/images'\ndef read_dcm(src_path):\n    dicom_data = pydicom.dcmread(src_path)\n    image = dicom_data.pixel_array\n    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n    return image\n\ndef convert_dcm_to_jpg(file_path):\n    try:\n        # Read the DICOM file\n        image_array = read_dcm(file_path)\n        \n        # Define the output path\n        relative_path = os.path.relpath(file_path, start=input_directory)\n        output_path = os.path.join(output_directory, relative_path)\n        output_path = output_path.replace('.dcm', '.jpg')\n                \n        # Create the output directory if it doesn't exist\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        # Save the image as a JPEG file\n        cv2.imwrite(output_path, image_array)\n        \n        return output_path\n    except Exception as e:\n        print(f\"Error processing file {file_path}: {e}\")\n        return None\n\ndef process_files(dcm_files):\n    with Pool(cpu_count()) as pool:\n        # Wrap pool.map with tqdm to show the progress bar\n        list(tqdm(pool.imap(convert_dcm_to_jpg, dcm_files), total=len(dcm_files)))\n\ndef get_dcm_files(directory):\n    dcm_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith('.dcm'):\n                dcm_files.append(os.path.join(root, file))\n    return dcm_files    \n\n\ninput_directory = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images'\n\noutput_directory = IMG_DIR\n\n# Get all .dcm files in the input directory\ndcm_files = get_dcm_files(input_directory)\n\n# Process the files using multiprocessing\nprocess_files(dcm_files)\n\nprint(f\"Conversion completed. Images saved to {output_directory}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:23:01.970422Z","iopub.execute_input":"2024-10-07T14:23:01.970755Z","iopub.status.idle":"2024-10-07T14:23:01.97893Z","shell.execute_reply.started":"2024-10-07T14:23:01.970726Z","shell.execute_reply":"2024-10-07T14:23:01.978047Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python convert_dcm.py","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:23:01.980071Z","iopub.execute_input":"2024-10-07T14:23:01.98036Z","iopub.status.idle":"2024-10-07T14:23:09.91543Z","shell.execute_reply.started":"2024-10-07T14:23:01.980336Z","shell.execute_reply":"2024-10-07T14:23:09.914503Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile infer.py \n\nimport sys\nmodel_dir = sys.argv[1]\nimg_size = int(sys.argv[2])\nfold_index = int(sys.argv[3])\nsave_file = sys.argv[4]\n#weight = sys.argv[5]\nprint(model_dir, img_size, fold_index)\n\nimport os\nimport pydicom\nfrom PIL import Image\nimport numpy as np\nfrom multiprocessing import Pool, cpu_count\n\nimport sklearn.metrics\nimport torch\nimport cv2\nimport numpy as np \nimport pandas as pd \nfrom tqdm.auto import tqdm\n\nEVAL = 0 \nIMG_DIR = '/images'\nFOLD = int(fold_index)\nSAMPLE = 0 \nSEVERITIES = ['Normal/Mild', 'Moderate', 'Severe']\nLEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n\nSCS_WEIGHTS = [f'{model_dir}/scs_fold{FOLD}_{img_size}_normal.pt']\nSS_WEIGHTS = [f'{model_dir}/ss_fold{FOLD}_{img_size}_normal.pt']\nNFN_WEIGHTS = [f'{model_dir}/nfn_fold{FOLD}_{img_size}_normal.pt']\n\nSCS_WEIGHTS += [f'{model_dir}/scs_fold{FOLD}_{img_size}_severe.pt']\nSS_WEIGHTS += [f'{model_dir}/ss_fold{FOLD}_{img_size}_severe.pt']\nNFN_WEIGHTS += [f'{model_dir}/nfn_fold{FOLD}_{img_size}_severe.pt']\n\nprint(SCS_WEIGHTS,'\\n', SS_WEIGHTS,'\\n', NFN_WEIGHTS)\n\ntrain_val_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\ndes = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\n\n\ntest_df = os.listdir('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images')\ntest_df = pd.DataFrame(test_df, columns=['study_id'])\ntest_df['study_id'] = test_df['study_id'].astype(int)\n    \ntest_df = test_df.merge(des, on=['study_id'])\n\ndef gen_label_map(CONDITIONS):\n    label2id = {}\n    id2label = {}\n    i = 0\n    for cond in CONDITIONS:\n        for level in LEVELS:\n            for severity in SEVERITIES:\n                cls_ = f\"{cond.lower().replace(' ', '_')}_{level}_{severity.lower()}\"\n                label2id[cls_] = i\n                id2label[i] = cls_\n                i+=1\n    return label2id, id2label\n                \nscs_label2id, scs_id2label = gen_label_map(['Spinal Canal Stenosis'])\nss_label2id, ss_id2label = gen_label_map(['Left Subarticular Stenosis', 'Right Subarticular Stenosis'])\nnfn_label2id, nfn_id2label = gen_label_map(['Left Neural Foraminal Narrowing', 'Right Neural Foraminal Narrowing'])\n\nfrom ultralytics import YOLO\n\n# Load YOLO Model\nscs_models = []\nfor weight in SCS_WEIGHTS:\n    scs_models.append(YOLO(weight))\n\nss_models = []\nfor weight in SS_WEIGHTS:\n    ss_models.append(YOLO(weight))\n\nnfn_models = []\nfor weight in NFN_WEIGHTS:\n    nfn_models.append(YOLO(weight))\n\nall_label_set = train_val_df.iloc[0, 1:].index.tolist()\nscs_label_set = all_label_set[:5]\nnfn_label_set = all_label_set[5:15]\nss_label_set = all_label_set[15:]\n\nsettings = [\n    ( 'Sagittal T2/STIR', scs_models, scs_id2label, scs_label_set, 0.01),\n    ( 'Axial T2', ss_models, ss_id2label, ss_label_set, 0.02),\n    ( 'Sagittal T1', nfn_models, nfn_id2label, nfn_label_set, 0.02)\n]\n\nfrom collections import defaultdict\n\npred_rows = []\n\nfor modality, models, id2label, label_set, thresh in settings:\n    mod_df = test_df[test_df.series_description == modality]\n    \n    if SAMPLE:\n        mod_df = mod_df.sample(20, random_state=610)\n    \n    # for each study, at each level and condition, get the maximum probability score\n    for study_id, group in tqdm(mod_df.groupby('study_id')):\n        predictions = defaultdict(list)\n        for i, row in group.iterrows():\n            # predict on all images from all the series\n            series_dir = os.path.join(IMG_DIR, str(row['study_id']), str(row['series_id']))\n            for model in models:\n                results = model(series_dir, imgsz=img_size, conf=thresh, verbose=False, augment=False, )\n                for res in results:\n                    for pred_class, conf in zip(res.boxes.cls, res.boxes.conf):\n                        pred_class = pred_class.item()\n                        conf = conf.item()\n                        _class = id2label[pred_class]\n                        predictions[_class].append(conf)\n        \n        # aggregate the result on images to obtain study-level prediction\n        for condition in label_set:\n            res_dict = {'row_id': f'{study_id}_{condition}' }\n\n            score_vec = []\n            for severity in SEVERITIES:\n                if severity=='Severe':\n                    scaler = 2.0\n                elif severity=='Moderate':\n                    scaler = 1.2\n                else:\n                    scaler = 0.85\n                severity = severity.lower()\n                key = f'{condition}_{severity}'\n                if len(predictions[key]) > 0:\n                    score = np.max(predictions[key])\n                else:\n                    score = thresh\n                    \n                if score>0.2:\n                    score = score*scaler\n                    \n                score_vec.append(score)\n                \n            # normalize score to sum to 1\n            score_vec = torch.tensor(score_vec)\n            score_vec = score_vec / score_vec.sum()\n\n            for idx, severity in enumerate(SEVERITIES):\n                res_dict[severity.replace('/', '_').lower()] = score_vec[idx].item()\n\n            pred_rows.append(res_dict)\n\n\npred_df = pd.DataFrame(pred_rows)\npred_df\n\npred_df.to_csv(save_file, index=False)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:23:09.917806Z","iopub.execute_input":"2024-10-07T14:23:09.918136Z","iopub.status.idle":"2024-10-07T14:23:09.928138Z","shell.execute_reply.started":"2024-10-07T14:23:09.918109Z","shell.execute_reply":"2024-10-07T14:23:09.927015Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#/kaggle/input/rsna2024-yolos4/nfn_fold0_384_normal.pt","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos4 384 0 pred7.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:23:10.001525Z","iopub.execute_input":"2024-10-07T14:23:10.001767Z","iopub.status.idle":"2024-10-07T14:23:25.384395Z","shell.execute_reply.started":"2024-10-07T14:23:10.001747Z","shell.execute_reply":"2024-10-07T14:23:25.383398Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos4 512 0 pred8.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:23:25.386023Z","iopub.execute_input":"2024-10-07T14:23:25.386862Z","iopub.status.idle":"2024-10-07T14:23:39.756977Z","shell.execute_reply.started":"2024-10-07T14:23:25.386824Z","shell.execute_reply":"2024-10-07T14:23:39.755878Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos4 768 0 pred9.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:23:39.758495Z","iopub.execute_input":"2024-10-07T14:23:39.758868Z","iopub.status.idle":"2024-10-07T14:23:54.722913Z","shell.execute_reply.started":"2024-10-07T14:23:39.758833Z","shell.execute_reply":"2024-10-07T14:23:54.721925Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos4 384 1 pred10.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:23:54.724496Z","iopub.execute_input":"2024-10-07T14:23:54.725627Z","iopub.status.idle":"2024-10-07T14:24:08.838142Z","shell.execute_reply.started":"2024-10-07T14:23:54.725588Z","shell.execute_reply":"2024-10-07T14:24:08.836978Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos4 512 1 pred11.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:24:08.839532Z","iopub.execute_input":"2024-10-07T14:24:08.839864Z","iopub.status.idle":"2024-10-07T14:24:22.995631Z","shell.execute_reply.started":"2024-10-07T14:24:08.839838Z","shell.execute_reply":"2024-10-07T14:24:22.994469Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos4 768 1 pred12.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:24:22.997195Z","iopub.execute_input":"2024-10-07T14:24:22.997914Z","iopub.status.idle":"2024-10-07T14:24:38.022752Z","shell.execute_reply.started":"2024-10-07T14:24:22.997877Z","shell.execute_reply":"2024-10-07T14:24:38.021809Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos3/yolov8m_last 384 0 pred13.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:24:38.030567Z","iopub.execute_input":"2024-10-07T14:24:38.031172Z","iopub.status.idle":"2024-10-07T14:24:54.538446Z","shell.execute_reply.started":"2024-10-07T14:24:38.03114Z","shell.execute_reply":"2024-10-07T14:24:54.536773Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos3/yolov8m_last 512 0 pred14.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:24:54.54054Z","iopub.execute_input":"2024-10-07T14:24:54.540941Z","iopub.status.idle":"2024-10-07T14:25:11.669911Z","shell.execute_reply.started":"2024-10-07T14:24:54.540905Z","shell.execute_reply":"2024-10-07T14:25:11.668889Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos3/yolov8m_last 384 1 pred15.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:25:11.671517Z","iopub.execute_input":"2024-10-07T14:25:11.671848Z","iopub.status.idle":"2024-10-07T14:25:28.574483Z","shell.execute_reply.started":"2024-10-07T14:25:11.671819Z","shell.execute_reply":"2024-10-07T14:25:28.573326Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer.py /kaggle/input/rsna2024-yolos3/yolov8m_last 512 1 pred16.csv","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:25:28.575942Z","iopub.execute_input":"2024-10-07T14:25:28.576275Z","iopub.status.idle":"2024-10-07T14:25:45.921419Z","shell.execute_reply.started":"2024-10-07T14:25:28.576248Z","shell.execute_reply":"2024-10-07T14:25:45.920492Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%%writefile yolo_ensemble.py\nimport glob\nimport pandas as pd\nsubs = glob.glob('/kaggle/working/pred*.csv')\npreds = []\nfor f in subs:\n    df = pd.read_csv(f)\n    preds.append(df)\npreds = pd.concat(preds, ignore_index=True)\npreds = preds.groupby(['row_id']).agg({'normal_mild':\"mean\", 'moderate':\"mean\", 'severe':\"mean\"}).sort_index().reset_index()\npreds.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T14:25:45.922848Z","iopub.execute_input":"2024-10-07T14:25:45.923159Z","iopub.status.idle":"2024-10-07T14:25:46.330775Z","shell.execute_reply.started":"2024-10-07T14:25:45.923133Z","shell.execute_reply":"2024-10-07T14:25:46.330038Z"},"trusted":true},"outputs":[],"execution_count":null}]}